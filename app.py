import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_fscore_support
import warnings
warnings.filterwarnings('ignore')

# Configuration de la page
st.set_page_config(
    page_title="Pr√©diction Statuts R√©servation Uber - Portfolio IA",
    page_icon="üöó",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personnalis√© pour am√©liorer l'apparence
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background: #f0f2f6;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #667eea;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 2px;
    }
    .stTabs [data-baseweb="tab"] {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 8px;
    }
    .success-metric {
        background: #d4edda;
        color: #155724;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #28a745;
        margin: 1rem 0;
    }
    .warning-metric {
        background: #fff3cd;
        color: #856404;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #ffc107;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

@st.cache_data
def load_data():
    """Charge les donn√©es r√©elles ou g√©n√®re des donn√©es de d√©monstration"""
    try:
        # Tentative de chargement de vos donn√©es r√©elles
        df = pd.read_csv('uber/archive/ncr_ride_bookings.csv')
        st.success("Donn√©es r√©elles charg√©es avec succ√®s!")
        return df
    except FileNotFoundError:
        st.warning("Fichier de donn√©es non trouv√©. Utilisation de donn√©es de d√©monstration.")
        return generate_demo_data()

@st.cache_data
def generate_demo_data():
    """G√©n√®re des donn√©es de d√©monstration r√©alistes"""
    np.random.seed(42)
    n_samples = 10000
    
    # G√©n√©ration de donn√©es synth√©tiques r√©alistes bas√©es sur le contexte Uber
    dates = pd.date_range('2023-01-01', periods=n_samples, freq='H')
    
    data = {
        'Date': [d.strftime('%Y-%m-%d') for d in dates],
        'Time': [d.strftime('%H:%M:%S') for d in dates],
        'Pickup Location': np.random.choice([
            'Airport', 'Downtown', 'Mall', 'Station', 'Hospital', 
            'Hotel', 'Office Complex', 'Residential Area'
        ], n_samples, p=[0.15, 0.25, 0.12, 0.10, 0.08, 0.10, 0.15, 0.05]),
        'Drop Location': np.random.choice([
            'Airport', 'Downtown', 'Mall', 'Station', 'Hospital', 
            'Hotel', 'Office Complex', 'Residential Area'
        ], n_samples, p=[0.12, 0.20, 0.15, 0.08, 0.05, 0.08, 0.12, 0.20]),
        'Ride Distance': np.random.exponential(8, n_samples) + 1,  # Distance en km
        'Booking Value': np.random.normal(28, 12, n_samples).clip(min=8),  # Prix en euros
        'Vehicle Type': np.random.choice([
            'Economy', 'Premium', 'Shared', 'Luxury'
        ], n_samples, p=[0.5, 0.25, 0.2, 0.05]),
        'Payment Method': np.random.choice([
            'Card', 'Cash', 'Wallet', 'Corporate'
        ], n_samples, p=[0.6, 0.25, 0.12, 0.03]),
        'Avg VTAT': np.random.normal(7, 3, n_samples).clip(min=1),  # Temps attente v√©hicule
        'Avg CTAT': np.random.normal(4, 2, n_samples).clip(min=1),  # Temps attente client
        'Booking Status': np.random.choice([
            'Success', 'Canceled by Driver', 'Canceled by Customer', 'No Show'
        ], n_samples, p=[0.75, 0.12, 0.10, 0.03])
    }
    
    return pd.DataFrame(data)

@st.cache_data
def preprocess_data(df):
    """Preprocessing complet des donn√©es"""
    df_processed = df.copy()
    
    # Feature engineering temporel
    df_processed['DateTime'] = pd.to_datetime(df_processed['Date'] + ' ' + df_processed['Time'])
    df_processed['Hour'] = df_processed['DateTime'].dt.hour
    df_processed['DayOfWeek'] = df_processed['DateTime'].dt.dayofweek
    df_processed['Month'] = df_processed['DateTime'].dt.month
    df_processed['IsWeekend'] = (df_processed['DayOfWeek'] >= 5).astype(int)
    
    def get_time_slot(hour):
        if 6 <= hour < 10:
            return 'Morning_Rush'
        elif 10 <= hour < 16:
            return 'Midday'
        elif 16 <= hour < 20:
            return 'Evening_Rush'
        elif 20 <= hour < 24:
            return 'Evening'
        else:
            return 'Night_EarlyMorning'
    
    df_processed['TimeSlot'] = df_processed['Hour'].apply(get_time_slot)
    
    # S√©lection des features pertinentes
    features = ['Pickup Location', 'Drop Location', 'Ride Distance', 'Booking Value',
                'Vehicle Type', 'Payment Method', 'Avg VTAT', 'Avg CTAT',
                'Hour', 'DayOfWeek', 'Month', 'IsWeekend', 'TimeSlot']
    
    X = df_processed[features].copy()
    y = df_processed['Booking Status'].copy()
    
    # Encodage des variables cat√©gorielles
    label_encoders = {}
    categorical_features = X.select_dtypes(include=['object']).columns
    
    for col in categorical_features:
        X[col] = X[col].fillna('MISSING')
        le = LabelEncoder()
        X[col] = le.fit_transform(X[col])
        label_encoders[col] = le
    
    # Encodage de la variable cible
    target_encoder = LabelEncoder()
    y_encoded = target_encoder.fit_transform(y)
    
    return X, y_encoded, target_encoder, label_encoders, df_processed

@st.cache_resource
def train_models(X, y):
    """Entra√Æne et √©value les mod√®les de machine learning"""
    # Division train/test stratifi√©e
    try:
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
    except ValueError:
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
    
    # Pipeline de preprocessing
    preprocessing = Pipeline([
        ('imputer', SimpleImputer(strategy='median')),
        ('scaler', StandardScaler())
    ])
    
    # Mod√®les √† √©valuer
    models = {
        'Random Forest': Pipeline([
            ('preprocessing', preprocessing),
            ('classifier', RandomForestClassifier(
                n_estimators=100, 
                random_state=42, 
                class_weight='balanced',
                n_jobs=-1
            ))
        ]),
        'Logistic Regression': Pipeline([
            ('preprocessing', preprocessing),
            ('classifier', LogisticRegression(
                max_iter=1000, 
                random_state=42, 
                class_weight='balanced'
            ))
        ])
    }
    
    results = {}
    for name, model in models.items():
        # Entra√Ænement
        model.fit(X_train, y_train)
        
        # Pr√©dictions
        y_pred = model.predict(X_test)
        y_pred_proba = model.predict_proba(X_test)
        
        # M√©triques
        accuracy = accuracy_score(y_test, y_pred)
        
        # Validation crois√©e
        try:
            cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')
        except:
            cv_scores = np.array([accuracy])  # Fallback
        
        results[name] = {
            'model': model,
            'accuracy': accuracy,
            'cv_mean': cv_scores.mean(),
            'cv_std': cv_scores.std(),
            'predictions': y_pred,
            'probabilities': y_pred_proba,
            'y_test': y_test
        }
    
    return results, X_train, X_test, y_train, y_test

def create_confusion_matrix_plot(y_test, y_pred, target_encoder):
    """Cr√©e une heatmap de la matrice de confusion"""
    cm = confusion_matrix(y_test, y_pred)
    
    fig = px.imshow(
        cm, 
        text_auto=True,
        aspect="auto",
        title="Matrice de Confusion",
        labels=dict(x="Pr√©dictions", y="Vraies Valeurs"),
        x=target_encoder.classes_,
        y=target_encoder.classes_,
        color_continuous_scale="Blues"
    )
    
    return fig

def create_feature_importance_plot(model, feature_names):
    """Cr√©e un graphique d'importance des features pour Random Forest"""
    if hasattr(model.named_steps['classifier'], 'feature_importances_'):
        importance = model.named_steps['classifier'].feature_importances_
        
        importance_df = pd.DataFrame({
            'Feature': feature_names,
            'Importance': importance
        }).sort_values('Importance', ascending=True)
        
        fig = px.bar(
            importance_df, 
            x='Importance', 
            y='Feature',
            orientation='h',
            title="Importance des Features (Random Forest)"
        )
        
        return fig
    return None

def main():
    # Header principal avec style
    st.markdown("""
    <div class="main-header">
        <h1>üöó Pr√©diction des Statuts de R√©servation Uber</h1>
        <p>Projet d'Intelligence Artificielle - Machine Learning</p>
        <p><strong>Par :</strong> Nadir Ali Ahmed | <strong>Portfolio Data Science</strong></p>
    </div>
    """, unsafe_allow_html=True)
    
    # Sidebar avec informations du projet
    st.sidebar.markdown("## üìä √Ä Propos du Projet")
    st.sidebar.markdown("""
    **Objectif :** Pr√©dire le statut des r√©servations Uber
    
    **Classes pr√©dites :**
    - ‚úÖ Succ√®s
    - ‚ùå Annul√© par chauffeur
    - ‚ùå Annul√© par client
    - ‚ö†Ô∏è No Show
    
    **Technologies :**
    - Python (Pandas, Scikit-learn)
    - Random Forest, R√©gression Logistique
    - Streamlit, Plotly
    
    **M√©thodologie :**
    1. Analyse exploratoire (EDA)
    2. Feature Engineering
    3. Preprocessing automatis√©
    4. Entra√Ænement de mod√®les
    5. √âvaluation comparative
    """)
    
    # Chargement des donn√©es avec feedback
    with st.spinner('Chargement et preprocessing des donn√©es...'):
        df = load_data()
        X, y, target_encoder, label_encoders, df_processed = preprocess_data(df)
        results, X_train, X_test, y_train, y_test = train_models(X, y)
    
    # Tabs principales de l'application
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "üìà Donn√©es", 
        "üîç EDA", 
        "ü§ñ Mod√®les", 
        "üìä Performance", 
        "üéØ Test Interactif",
        "üìã Rapport Final"
    ])
    
    with tab1:
        st.header("üìà Aper√ßu des Donn√©es")
        
        # M√©triques principales
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Observations", f"{len(df):,}")
        with col2:
            st.metric("Features", f"{len(X.columns)}")
        with col3:
            st.metric("Classes", f"{len(target_encoder.classes_)}")
        with col4:
            success_rate = (df['Booking Status'] == 'Success').mean() * 100
            st.metric("Taux Succ√®s", f"{success_rate:.1f}%")
        
        # √âchantillon des donn√©es
        st.subheader("√âchantillon des donn√©es originales")
        st.dataframe(df.head(10), use_container_width=True)
        
        # Distribution de la variable cible
        st.subheader("Distribution de la variable cible")
        target_dist = df['Booking Status'].value_counts()
        
        col1, col2 = st.columns(2)
        with col1:
            fig = px.pie(
                values=target_dist.values, 
                names=target_dist.index,
                title="R√©partition des Statuts"
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            fig = px.bar(
                x=target_dist.index, 
                y=target_dist.values,
                title="Effectifs par Statut",
                labels={'x': 'Statut', 'y': 'Nombre de r√©servations'}
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # Statistiques descriptives
        st.subheader("Statistiques descriptives")
        st.dataframe(df.describe(), use_container_width=True)
    
    with tab2:
        st.header("üîç Analyse Exploratoire des Donn√©es")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("R√©servations par heure")
            hourly_data = df_processed.groupby('Hour').size()
            fig = px.line(
                x=hourly_data.index, 
                y=hourly_data.values,
                title="Volume de r√©servations par heure",
                labels={'x': 'Heure', 'y': 'Nombre de r√©servations'}
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.subheader("Statuts par jour de la semaine")
            days = ['Lun', 'Mar', 'Mer', 'Jeu', 'Ven', 'Sam', 'Dim']
            weekly_data = pd.crosstab(df_processed['DayOfWeek'], df['Booking Status'])
            weekly_data.index = days
            fig = px.bar(weekly_data, title="Statuts par jour de la semaine")
            st.plotly_chart(fig, use_container_width=True)
        
        col3, col4 = st.columns(2)
        
        with col3:
            st.subheader("Distribution des distances")
            fig = px.histogram(
                df, 
                x='Ride Distance', 
                title="Distribution des distances de trajet",
                nbins=50
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col4:
            st.subheader("Valeur moyenne par type de v√©hicule")
            vehicle_stats = df.groupby('Vehicle Type')['Booking Value'].mean().sort_values(ascending=False)
            fig = px.bar(
                x=vehicle_stats.values,
                y=vehicle_stats.index,
                orientation='h',
                title="Valeur moyenne par type de v√©hicule"
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # Corr√©lations
        st.subheader("Matrice de corr√©lation des variables num√©riques")
        numeric_cols = ['Ride Distance', 'Booking Value', 'Avg VTAT', 'Avg CTAT', 'Hour']
        if all(col in df.columns for col in numeric_cols):
            corr_matrix = df[numeric_cols].corr()
            fig = px.imshow(
                corr_matrix, 
                title="Corr√©lations entre variables num√©riques",
                color_continuous_scale="RdBu_r",
                aspect="auto"
            )
            st.plotly_chart(fig, use_container_width=True)
    
    with tab3:
        st.header("ü§ñ Mod√®les d'Intelligence Artificielle")
        
        st.markdown("""
        ### üõ†Ô∏è M√©thodologie de D√©veloppement
        
        **1. Feature Engineering :**
        - Extraction temporelle : heure, jour semaine, cr√©neaux horaires
        - Variables d√©riv√©es : weekend, rush hours
        - Encodage des variables cat√©gorielles
        
        **2. Preprocessing :**
        - Gestion des valeurs manquantes (m√©diane)
        - Standardisation des features num√©riques
        - Pipeline int√©gr√© pour √©viter le data leakage
        
        **3. Mod√®les test√©s :**
        - **Random Forest** : Ensemble d'arbres de d√©cision
        - **R√©gression Logistique** : Mod√®le lin√©aire probabiliste
        
        **4. Validation :**
        - Division train/test stratifi√©e (80/20)
        - Validation crois√©e 5-fold
        - √âquilibrage des classes (class_weight='balanced')
        """)
        
        # Comparaison des performances
        st.subheader("üèÜ Comparaison des Performances")
        
        model_comparison = []
        for name, result in results.items():
            model_comparison.append({
                'Mod√®le': name,
                'Accuracy': result['accuracy'],
                'CV Mean': result['cv_mean'],
                'CV Std': result['cv_std']
            })
        
        comparison_df = pd.DataFrame(model_comparison)
        
        col1, col2 = st.columns(2)
        with col1:
            st.dataframe(
                comparison_df.style.format({
                    'Accuracy': '{:.4f}',
                    'CV Mean': '{:.4f}',
                    'CV Std': '{:.4f}'
                }),
                use_container_width=True
            )
        
        with col2:
            fig = px.bar(
                comparison_df, 
                x='Mod√®le', 
                y='Accuracy',
                title="Accuracy par mod√®le",
                color='Accuracy',
                color_continuous_scale='viridis'
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # Meilleur mod√®le
        best_model_name = max(results.keys(), key=lambda x: results[x]['accuracy'])
        st.markdown(f"""
        <div class="success-metric">
            <h4>üèÜ Meilleur Mod√®le : {best_model_name}</h4>
            <p>Accuracy: {results[best_model_name]['accuracy']:.4f} ({results[best_model_name]['accuracy']*100:.2f}%)</p>
        </div>
        """, unsafe_allow_html=True)
    
    with tab4:
        st.header("üìä Analyse D√©taill√©e des Performances")
        
        # S√©lection du meilleur mod√®le
        best_model_name = max(results.keys(), key=lambda x: results[x]['accuracy'])
        best_result = results[best_model_name]
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Matrice de Confusion")
            fig = create_confusion_matrix_plot(
                best_result['y_test'], 
                best_result['predictions'], 
                target_encoder
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.subheader("M√©triques par Classe")
            report = classification_report(
                best_result['y_test'], 
                best_result['predictions'], 
                target_names=target_encoder.classes_, 
                output_dict=True
            )
            
            report_df = pd.DataFrame(report).transpose().round(3)
            st.dataframe(report_df, use_container_width=True)
        
        # Importance des features (si Random Forest)
        if 'Random Forest' in best_model_name:
            st.subheader("Importance des Features")
            fig = create_feature_importance_plot(best_result['model'], X.columns)
            if fig:
                st.plotly_chart(fig, use_container_width=True)
        
        # Analyse des erreurs
        st.subheader("Analyse des Erreurs")
        cm = confusion_matrix(best_result['y_test'], best_result['predictions'])
        total_errors = len(best_result['y_test']) - cm.trace()
        error_rate = total_errors / len(best_result['y_test'])
        
        st.markdown(f"""
        **Statistiques d'erreur :**
        - Erreurs totales : {total_errors}
        - Taux d'erreur : {error_rate:.3f} ({error_rate*100:.1f}%)
        - Pr√©dictions correctes : {cm.trace()} / {len(best_result['y_test'])}
        """)
    
    with tab5:
        st.header("üéØ Test Interactif du Mod√®le")
        st.markdown("Testez le mod√®le avec vos propres param√®tres et obtenez une pr√©diction en temps r√©el !")
        
        # Interface de test
        col1, col2, col3 = st.columns(3)
        
        with col1:
            pickup = st.selectbox("Lieu de d√©part", [
                'Airport', 'Downtown', 'Mall', 'Station', 'Hospital', 
                'Hotel', 'Office Complex', 'Residential Area'
            ])
            drop = st.selectbox("Destination", [
                'Airport', 'Downtown', 'Mall', 'Station', 'Hospital', 
                'Hotel', 'Office Complex', 'Residential Area'
            ])
            distance = st.slider("Distance (km)", 1.0, 50.0, 10.0, 0.5)
            booking_value = st.slider("Valeur de la course (‚Ç¨)", 5.0, 100.0, 25.0, 1.0)
            vehicle_type = st.selectbox("Type de v√©hicule", [
                'Economy', 'Premium', 'Shared', 'Luxury'
            ])
        
        with col2:
            payment = st.selectbox("M√©thode de paiement", [
                'Card', 'Cash', 'Wallet', 'Corporate'
            ])
            hour = st.slider("Heure de la r√©servation", 0, 23, 12)
            day_of_week = st.selectbox("Jour de la semaine", [
                'Lundi', 'Mardi', 'Mercredi', 'Jeudi', 'Vendredi', 'Samedi', 'Dimanche'
            ])
            avg_vtat = st.slider("Temps d'attente v√©hicule (min)", 1.0, 20.0, 7.0, 0.5)
            avg_ctat = st.slider("Temps d'attente client (min)", 1.0, 15.0, 4.0, 0.5)
        
        with col3:
            st.markdown("### Contexte de la pr√©diction")
            st.info(f"""
            **Trajet :** {pickup} ‚Üí {drop}  
            **Distance :** {distance} km  
            **Valeur :** {booking_value}‚Ç¨  
            **V√©hicule :** {vehicle_type}  
            **Heure :** {hour}h ({day_of_week})
            """)
        
        if st.button("üîÆ Pr√©dire le Statut", type="primary", use_container_width=True):
            # Pr√©paration des donn√©es pour pr√©diction
            day_mapping = {
                'Lundi': 0, 'Mardi': 1, 'Mercredi': 2, 'Jeudi': 3, 
                'Vendredi': 4, 'Samedi': 5, 'Dimanche': 6
            }
            
            def get_time_slot(hour):
                if 6 <= hour < 10:
                    return 'Morning_Rush'
                elif 10 <= hour < 16:
                    return 'Midday'
                elif 16 <= hour < 20:
                    return 'Evening_Rush'
                elif 20 <= hour < 24:
                    return 'Evening'
                else:
                    return 'Night_EarlyMorning'
            
            # Construction de l'√©chantillon de test
            test_data = {
                'Pickup Location': pickup,
                'Drop Location': drop,
                'Ride Distance': distance,
                'Booking Value': booking_value,
                'Vehicle Type': vehicle_type,
                'Payment Method': payment,
                'Avg VTAT': avg_vtat,
                'Avg CTAT': avg_ctat,
                'Hour': hour,
                'DayOfWeek': day_mapping[day_of_week],
                'Month': 6,  # Valeur par d√©faut
                'IsWeekend': 1 if day_mapping[day_of_week] >= 5 else 0,
                'TimeSlot': get_time_slot(hour)
            }
            
            # Encodage des variables cat√©gorielles
            for col, encoder in label_encoders.items():
                if col in test_data:
                    try:
                        if test_data[col] in encoder.classes_:
                            test_data[col] = encoder.transform([test_data[col]])[0]
                        else:
                            test_data[col] = 0  # Valeur par d√©faut
                    except:
                        test_data[col] = 0
            
            # Pr√©diction avec le meilleur mod√®le
            test_df = pd.DataFrame([test_data])
            best_model = results[best_model_name]['model']
            
            try:
                prediction = best_model.predict(test_df)[0]
                prediction_proba = best_model.predict_proba(test_df)[0]
                predicted_class = target_encoder.inverse_transform([prediction])[0]
                
                # Affichage du r√©sultat
                max_proba = np.max(prediction_proba)
                
                if predicted_class == 'Success':
                    st.success(f"üéâ **Pr√©diction : {predicted_class}** (Confiance: {max_proba:.1%})")
                else:
                    st.error(f"‚ö†Ô∏è **Pr√©diction : {predicted_class}** (Confiance: {max_proba:.1%})")
                
                # Graphique des probabilit√©s
                proba_df = pd.DataFrame({
                    'Statut': target_encoder.classes_,
                    'Probabilit√©': prediction_proba
                }).sort_values('Probabilit√©', ascending=True)
                
                fig = px.bar(
                    proba_df, 
                    x='Probabilit√©', 
                    y='Statut',
                    orientation='h',
                    title="Distribution des probabilit√©s",
                    color='Probabilit√©',
                    color_continuous_scale='viridis'
                )
                st.plotly_chart(fig, use_container_width=True)
                
            except Exception as e:
                st.error(f"Erreur lors de la pr√©diction: {e}")
    
    with tab6:
        st.header("üìã Rapport Final du Projet")
        
        # M√©triques de performance finales
        best_model_name = max(results.keys(), key=lambda x: results[x]['accuracy'])
        best_accuracy = results[best_model_name]['accuracy']
        
        st.markdown("""
        ## üéØ Objectifs du Projet
        D√©velopper un mod√®le de machine learning capable de pr√©dire avec pr√©cision 
        le statut des r√©servations Uber pour optimiser les op√©rations et am√©liorer 
        l'exp√©rience utilisateur.
        """)
        
        # R√©sultats principaux
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown(f"""
            <div class="success-metric">
                <h4>üèÜ Mod√®le Final</h4>
                <p><strong>{best_model_name}</strong></p>
                <p>Accuracy: {best_accuracy:.3f} ({best_accuracy*100:.1f}%)</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            total_predictions = len(results[best_model_name]['y_test'])
            correct_predictions = int(best_accuracy * total_predictions)
            st.markdown(f"""
            <div class="metric-card">
                <h4>üìä Performance Test</h4>
                <p>{correct_predictions}/{total_predictions} pr√©dictions correctes</p>
                <p>Sur ensemble de validation</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            cv_mean = results[best_model_name]['cv_mean']
            st.markdown(f"""
            <div class="metric-card">
                <h4>üîÑ Validation Crois√©e</h4>
                <p>Moyenne: {cv_mean:.3f}</p>
                <p>Stabilit√© confirm√©e</p>
            </div>
            """, unsafe_allow_html=True)
        
        # Forces et am√©liorations
        st.markdown("## ‚úÖ Points Forts du Projet")
        st.markdown("""
        - **Feature Engineering avanc√©** : Extraction de patterns temporels pertinents
        - **Pipeline robuste** : Preprocessing automatis√© √©vitant le data leakage
        - **Validation rigoureuse** : Train/test stratifi√© + validation crois√©e
        - **Interface utilisateur** : Application interactive pour tests en temps r√©el
        - **Documentation compl√®te** : Code comment√© et rapport d√©taill√©
        """)
        
        st.markdown("## üîß Am√©liorations Possibles")
        st.markdown("""
        - **Donn√©es externes** : Int√©gration m√©t√©o, trafic, √©v√©nements
        - **Deep Learning** : Test de r√©seaux de neurones pour patterns complexes
        - **Optimisation hyperparam√®tres** : Grid search ou optimisation bay√©sienne
        - **Features g√©ospatiales** : Analyse de la densit√© des zones
        - **Mod√®les ensemblistes** : Stacking ou blending de mod√®les
        """)
        
        st.markdown("## üöÄ Impact Business")
        st.markdown("""
        Ce mod√®le peut √™tre utilis√© pour :
        - **Optimisation des ressources** : Allocation des chauffeurs aux zones √† fort succ√®s
        - **Pr√©vention des annulations** : Identification des r√©servations √† risque
        - **Am√©lioration UX** : Estimation des temps d'attente r√©alistes
        - **Strat√©gie pricing** : Ajustement des tarifs selon probabilit√© de succ√®s
        """)
        
        # Contact et portfolio
        st.markdown("---")
        st.markdown("""
        ### üë®‚Äçüíª Contact & Portfolio
        
        **D√©velopp√© par :** Nadir Ali Ahmed  
        **Email :** [Votre email]  
        **LinkedIn :** [Votre profil LinkedIn]  
        **GitHub :** [Repository du projet]  
        
        *Ce projet fait partie de mon portfolio data science. 
        Il d√©montre mes comp√©tences en machine learning, data preprocessing, 
        et d√©veloppement d'applications interactives.*
        """)

if __name__ == "__main__":
    main()